{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Boston Crime Data - Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook presents a comprehensive Exploratory Data Analysis (EDA) of Boston crime incident data. The dataset contains detailed information about various types of crimes and incidents reported in Boston, including temporal, geographical, and categorical attributes.\n",
        "\n",
        "### What is EDA?\n",
        "Exploratory Data Analysis is a critical step in data science that involves examining and understanding data through statistical summaries, visualizations, and pattern identification. It helps us:\n",
        "- Understand the structure and quality of our data\n",
        "- Identify patterns, trends, and anomalies\n",
        "- Generate hypotheses for further analysis\n",
        "- Prepare data for more advanced modeling\n",
        "\n",
        "### Dataset Overview\n",
        "The Boston crime dataset includes the following key information:\n",
        "- **Temporal data**: Date, time, year, month, day of week, hour\n",
        "- **Geographical data**: District, street, latitude, longitude\n",
        "- **Categorical data**: Offense types, descriptions, UCR classification\n",
        "- **Incident details**: Shooting incidents, reporting areas, incident numbers\n",
        "\n",
        "### Goals of This Analysis\n",
        "1. **Data Quality Assessment**: Identify missing values, data inconsistencies, and cleaning requirements\n",
        "2. **Temporal Patterns**: Understand when crimes occur (time of day, day of week, seasonal trends)\n",
        "3. **Geographical Distribution**: Analyze crime patterns across different districts and locations\n",
        "4. **Crime Type Analysis**: Examine the distribution and characteristics of different offense types\n",
        "5. **Shooting Incidents**: Special focus on violent crimes and their patterns\n",
        "6. **Correlation Analysis**: Identify relationships between different variables\n",
        "\n",
        "This analysis will provide valuable insights for law enforcement, urban planning, and public safety initiatives in Boston.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading & Setup\n",
        "\n",
        "In this section, we'll import the necessary libraries and load our crime dataset for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for data analysis and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import folium\n",
        "from folium import plugins\n",
        "\n",
        "# Set up plotting parameters for better visualization\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the crime data CSV file\n",
        "df = pd.read_csv('boston_crime_data_20250927_123841.csv')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning & Preprocessing\n",
        "\n",
        "Before diving into analysis, we need to clean and preprocess our data to ensure quality and consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values in the dataset\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
        "print(f\"Percentage of missing values: {(df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle missing values in OFFENSE_CODE_GROUP\n",
        "print(\"OFFENSE_CODE_GROUP missing values before cleaning:\", df['OFFENSE_CODE_GROUP'].isnull().sum())\n",
        "df['OFFENSE_CODE_GROUP'] = df['OFFENSE_CODE_GROUP'].fillna('Unknown')\n",
        "print(\"OFFENSE_CODE_GROUP missing values after cleaning:\", df['OFFENSE_CODE_GROUP'].isnull().sum())\n",
        "\n",
        "# Convert OCCURRED_ON_DATE to datetime\n",
        "print(\"\\nConverting OCCURRED_ON_DATE to datetime...\")\n",
        "df['OCCURRED_ON_DATE'] = pd.to_datetime(df['OCCURRED_ON_DATE'])\n",
        "print(\"Date conversion completed successfully!\")\n",
        "\n",
        "# Strip whitespace from column names\n",
        "print(\"\\nStripping whitespace from column names...\")\n",
        "df.columns = df.columns.str.strip()\n",
        "print(\"Column names after stripping whitespace:\")\n",
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional data cleaning steps\n",
        "# Remove any duplicate rows\n",
        "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
        "df = df.drop_duplicates()\n",
        "print(\"Number of rows after removing duplicates:\", len(df))\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Clean string columns by stripping whitespace\n",
        "string_columns = ['DISTRICT', 'OFFENSE_DESCRIPTION', 'DAY_OF_WEEK', 'STREET']\n",
        "for col in string_columns:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "print(\"\\nData cleaning completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Data Overview\n",
        "\n",
        "Let's get a comprehensive understanding of our dataset through statistical summaries and data exploration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display comprehensive summary statistics\n",
        "print(\"=== COMPREHENSIVE SUMMARY STATISTICS ===\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "print(\"\\n=== DATASET INFORMATION ===\")\n",
        "print(f\"Total number of records: {len(df):,}\")\n",
        "print(f\"Date range: {df['OCCURRED_ON_DATE'].min()} to {df['OCCURRED_ON_DATE'].max()}\")\n",
        "print(f\"Number of unique incidents: {df['INCIDENT_NUMBER'].nunique():,}\")\n",
        "print(f\"Number of unique districts: {df['DISTRICT'].nunique()}\")\n",
        "print(f\"Number of unique offense types: {df['OFFENSE_DESCRIPTION'].nunique()}\")\n",
        "print(f\"Number of shooting incidents: {df['SHOOTING'].sum():,}\")\n",
        "print(f\"Percentage of shooting incidents: {(df['SHOOTING'].sum() / len(df)) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count unique values for categorical columns\n",
        "print(\"=== CATEGORICAL COLUMNS ANALYSIS ===\")\n",
        "print(\"\\nDistricts:\")\n",
        "district_counts = df['DISTRICT'].value_counts()\n",
        "print(district_counts)\n",
        "\n",
        "print(\"\\nDay of Week:\")\n",
        "day_counts = df['DAY_OF_WEEK'].value_counts()\n",
        "print(day_counts)\n",
        "\n",
        "print(\"\\nTop 10 Offense Descriptions:\")\n",
        "offense_counts = df['OFFENSE_DESCRIPTION'].value_counts().head(10)\n",
        "print(offense_counts)\n",
        "\n",
        "print(\"\\nOffense Code Groups:\")\n",
        "offense_group_counts = df['OFFENSE_CODE_GROUP'].value_counts()\n",
        "print(offense_group_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Univariate Analysis\n",
        "\n",
        "In this section, we'll analyze individual variables to understand their distributions and characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of incidents by district\n",
        "plt.figure(figsize=(14, 8))\n",
        "district_counts = df['DISTRICT'].value_counts()\n",
        "bars = plt.bar(district_counts.index, district_counts.values, color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "plt.title('Distribution of Incidents by District', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('District', fontsize=12)\n",
        "plt.ylabel('Number of Incidents', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "             f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"District with most incidents: {district_counts.index[0]} ({district_counts.iloc[0]:,} incidents)\")\n",
        "print(f\"District with least incidents: {district_counts.index[-1]} ({district_counts.iloc[-1]:,} incidents)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of incidents by day of week (ordered from Monday to Sunday)\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Define the correct order for days of the week\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "day_counts = df['DAY_OF_WEEK'].value_counts()\n",
        "\n",
        "# Reorder the data according to the day order\n",
        "day_counts_ordered = day_counts.reindex(day_order)\n",
        "\n",
        "bars = plt.bar(day_counts_ordered.index, day_counts_ordered.values, \n",
        "               color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
        "plt.title('Distribution of Incidents by Day of Week', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Day of Week', fontsize=12)\n",
        "plt.ylabel('Number of Incidents', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "             f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Day of week with most incidents:\", day_counts_ordered.index[0])\n",
        "print(\"Day of week with least incidents:\", day_counts_ordered.index[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of incidents by hour of day\n",
        "plt.figure(figsize=(14, 8))\n",
        "hour_counts = df['HOUR'].value_counts().sort_index()\n",
        "\n",
        "bars = plt.bar(hour_counts.index, hour_counts.values, \n",
        "               color='lightgreen', edgecolor='darkgreen', alpha=0.7)\n",
        "plt.title('Distribution of Incidents by Hour of Day', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Hour of Day', fontsize=12)\n",
        "plt.ylabel('Number of Incidents', fontsize=12)\n",
        "plt.xticks(range(0, 24))\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars (only for every 2nd hour to avoid crowding)\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    if i % 2 == 0:  # Only label every 2nd bar\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                 f'{int(height):,}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Hour with most incidents: {hour_counts.idxmax()}:00 ({hour_counts.max():,} incidents)\")\n",
        "print(f\"Hour with least incidents: {hour_counts.idxmin()}:00 ({hour_counts.min():,} incidents)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 10 offense descriptions (horizontal bar chart)\n",
        "plt.figure(figsize=(12, 10))\n",
        "top_offenses = df['OFFENSE_DESCRIPTION'].value_counts().head(10)\n",
        "\n",
        "bars = plt.barh(range(len(top_offenses)), top_offenses.values, \n",
        "                color='gold', edgecolor='orange', alpha=0.7)\n",
        "plt.title('Top 10 Offense Descriptions', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Number of Incidents', fontsize=12)\n",
        "plt.ylabel('Offense Description', fontsize=12)\n",
        "plt.yticks(range(len(top_offenses)), top_offenses.index)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, bar in enumerate(bars):\n",
        "    width = bar.get_width()\n",
        "    plt.text(width + width*0.01, bar.get_y() + bar.get_height()/2.,\n",
        "             f'{int(width):,}', ha='left', va='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Top 5 most common offenses:\")\n",
        "for i, (offense, count) in enumerate(top_offenses.head(5).items(), 1):\n",
        "    print(f\"{i}. {offense}: {count:,} incidents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
